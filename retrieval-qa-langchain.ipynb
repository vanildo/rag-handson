{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import loggingService\n",
    "\n",
    "from genai.extensions.langchain import LangChainInterface\n",
    "from genai.model import Credentials\n",
    "from genai.schemas import GenerateParams\n",
    "\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain import PromptTemplate\n",
    "from langchain.chains import RetrievalQA, ConversationalRetrievalChain\n",
    "from langchain.vectorstores import Weaviate\n",
    "\n",
    "import os\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import weaviate\n",
    "\n",
    "load_dotenv()\n",
    "logger = loggingService.get_logger()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = os.getenv(\"GENAI_KEY\", None)\n",
    "api_endpoint = os.getenv(\"GENAI_API\", 'https://workbench-api.res.ibm.com')\n",
    "# class_name = os.getenv(\"WEVIATE_CLASS\", 'LivrosVectorizer')\n",
    "print(f\"API Key: {api_key}, API Endpoint: {api_endpoint}\")\n",
    "class_name ='Livros'\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\",input_key=\"question\", output_key='answer', return_messages=True)\n",
    "model_name = os.getenv('MODEL_NAME', 'bigscience/mt0-xxl')\n",
    "model_name_embedding = os.getenv(\"MODEL_NAME_EMBEDDING\", \"sentence-transformers/gtr-t5-large\")\n",
    "weaviate_url = os.getenv(\"WEAVIATE_URL\", 'http://127.0.0.1:8080')\n",
    "\n",
    "client = weaviate.Client(url=weaviate_url,)\n",
    "embeddings = SentenceTransformer(model_name_embedding)\n",
    "\n",
    "creds = Credentials(api_key, api_endpoint=api_endpoint)\n",
    "params = GenerateParams(\n",
    "    decoding_method=\"sample\",\n",
    "    max_new_tokens=100,\n",
    "    min_new_tokens=1,\n",
    "    stream=False,\n",
    "    temperature=0.5,\n",
    "    top_k=50,\n",
    "    top_p=1,\n",
    ").dict()  # Langchain uses dictionaries to pass kwargs\n",
    "\n",
    "llm = LangChainInterface(model=model_name, credentials=creds, params=params)\n",
    "vector_store = Weaviate(client=client, index_name='Livros', text_key='content')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vector_store.similarity_search_by_vector(embeddings.encode('por que arthur dent foi despejado?'))\n",
    "vector_store.similarity_search('por que a casa de arthur dent foi demolida?')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt1 = \"\"\"Responda a pergunta a seguir de forma sucinta usando o contexto e histórico fornecidos. Caso não tenha certeza da resposta siceramente diga que não possui informações suficientes sobre esse tema.\n",
    "\n",
    "Contexto: {context}\n",
    "\n",
    "Histórico: {chat_history}\n",
    "\n",
    "Pergunta: {question}\n",
    "\n",
    "Resposta:\"\"\"\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"context\", \"question\", \"chat_history\"],\n",
    "    template=pt1,\n",
    ")\n",
    "\n",
    "retriver = vector_store.as_retriever(search_kwargs={'score_threshold': 0.8})\n",
    "# chain_type_kwargs={\"prompt\": prompt},\n",
    "qa = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=retriver, memory=memory,  verbose=True)\n",
    "# qa = ConversationalRetrievalChain(llm=llm, retriever=retriver, memory=memory,  verbose=True, output_key='Resposta')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa.run('por que arthur dent foi despejado?')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
