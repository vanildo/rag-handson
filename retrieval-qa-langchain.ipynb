{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'transformers'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/Users/vanildovanni/projetos/foundation-models/rag-handson/code/retrieval-qa-langchain.ipynb Cell 1\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/vanildovanni/projetos/foundation-models/rag-handson/code/retrieval-qa-langchain.ipynb#W0sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mlangchain\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mvectorstores\u001b[39;00m \u001b[39mimport\u001b[39;00m Weaviate\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/vanildovanni/projetos/foundation-models/rag-handson/code/retrieval-qa-langchain.ipynb#W0sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mos\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/vanildovanni/projetos/foundation-models/rag-handson/code/retrieval-qa-langchain.ipynb#W0sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msentence_transformers\u001b[39;00m \u001b[39mimport\u001b[39;00m SentenceTransformer\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/vanildovanni/projetos/foundation-models/rag-handson/code/retrieval-qa-langchain.ipynb#W0sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mweaviate\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/vanildovanni/projetos/foundation-models/rag-handson/code/retrieval-qa-langchain.ipynb#W0sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m load_dotenv()\n",
      "File \u001b[0;32m~/conda3/envs/ml/lib/python3.11/site-packages/sentence_transformers/__init__.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m __version__ \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m2.2.2\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m      2\u001b[0m __MODEL_HUB_ORGANIZATION__ \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39msentence-transformers\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m----> 3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mdatasets\u001b[39;00m \u001b[39mimport\u001b[39;00m SentencesDataset, ParallelSentencesDataset\n\u001b[1;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mLoggingHandler\u001b[39;00m \u001b[39mimport\u001b[39;00m LoggingHandler\n\u001b[1;32m      5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mSentenceTransformer\u001b[39;00m \u001b[39mimport\u001b[39;00m SentenceTransformer\n",
      "File \u001b[0;32m~/conda3/envs/ml/lib/python3.11/site-packages/sentence_transformers/datasets/__init__.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mDenoisingAutoEncoderDataset\u001b[39;00m \u001b[39mimport\u001b[39;00m DenoisingAutoEncoderDataset\n\u001b[1;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mNoDuplicatesDataLoader\u001b[39;00m \u001b[39mimport\u001b[39;00m NoDuplicatesDataLoader\n\u001b[0;32m----> 3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mParallelSentencesDataset\u001b[39;00m \u001b[39mimport\u001b[39;00m ParallelSentencesDataset\n\u001b[1;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mSentencesDataset\u001b[39;00m \u001b[39mimport\u001b[39;00m SentencesDataset\n\u001b[1;32m      5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mSentenceLabelDataset\u001b[39;00m \u001b[39mimport\u001b[39;00m SentenceLabelDataset\n",
      "File \u001b[0;32m~/conda3/envs/ml/lib/python3.11/site-packages/sentence_transformers/datasets/ParallelSentencesDataset.py:4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mlogging\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mgzip\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m SentenceTransformer\n\u001b[1;32m      5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mreaders\u001b[39;00m \u001b[39mimport\u001b[39;00m InputExample\n\u001b[1;32m      6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtyping\u001b[39;00m \u001b[39mimport\u001b[39;00m List\n",
      "File \u001b[0;32m~/conda3/envs/ml/lib/python3.11/site-packages/sentence_transformers/SentenceTransformer.py:11\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mimport\u001b[39;00m ndarray\n\u001b[0;32m---> 11\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtransformers\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mhuggingface_hub\u001b[39;00m \u001b[39mimport\u001b[39;00m HfApi, HfFolder, Repository, hf_hub_url, cached_download\n\u001b[1;32m     13\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'transformers'"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import loggingService\n",
    "\n",
    "from genai.extensions.langchain import LangChainInterface\n",
    "from genai.model import Credentials\n",
    "from genai.schemas import GenerateParams\n",
    "\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain import PromptTemplate\n",
    "from langchain.chains import RetrievalQA, ConversationalRetrievalChain\n",
    "from langchain.vectorstores import Weaviate\n",
    "\n",
    "import os\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import weaviate\n",
    "\n",
    "load_dotenv()\n",
    "logger = loggingService.get_logger()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = os.getenv(\"GENAI_KEY\", None)\n",
    "api_endpoint = os.getenv(\"GENAI_API\", 'https://workbench-api.res.ibm.com')\n",
    "# class_name = os.getenv(\"WEVIATE_CLASS\", 'LivrosVectorizer')\n",
    "print(f\"API Key: {api_key}, API Endpoint: {api_endpoint}\")\n",
    "class_name ='Livros'\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\",input_key=\"question\", output_key='answer', return_messages=True)\n",
    "model_name = os.getenv('MODEL_NAME', 'bigscience/mt0-xxl')\n",
    "model_name_embedding = os.getenv(\"MODEL_NAME_EMBEDDING\", \"sentence-transformers/gtr-t5-large\")\n",
    "weaviate_url = os.getenv(\"WEAVIATE_URL\", 'http://127.0.0.1:8080')\n",
    "\n",
    "client = weaviate.Client(url=weaviate_url,)\n",
    "embeddings = SentenceTransformer(model_name_embedding)\n",
    "\n",
    "creds = Credentials(api_key, api_endpoint=api_endpoint)\n",
    "params = GenerateParams(\n",
    "    decoding_method=\"sample\",\n",
    "    max_new_tokens=100,\n",
    "    min_new_tokens=1,\n",
    "    stream=False,\n",
    "    temperature=0.5,\n",
    "    top_k=50,\n",
    "    top_p=1,\n",
    ").dict()  # Langchain uses dictionaries to pass kwargs\n",
    "\n",
    "llm = LangChainInterface(model=model_name, credentials=creds, params=params)\n",
    "vector_store = Weaviate(client=client, index_name='Livros', text_key='content')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vector_store.similarity_search_by_vector(embeddings.encode('por que arthur dent foi despejado?'))\n",
    "vector_store.similarity_search('por que a casa de arthur dent foi demolida?')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt1 = \"\"\"Responda a pergunta a seguir de forma sucinta usando o contexto e histórico fornecidos. Caso não tenha certeza da resposta siceramente diga que não possui informações suficientes sobre esse tema.\n",
    "\n",
    "Contexto: {context}\n",
    "\n",
    "Histórico: {chat_history}\n",
    "\n",
    "Pergunta: {question}\n",
    "\n",
    "Resposta:\"\"\"\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"context\", \"question\", \"chat_history\"],\n",
    "    template=pt1,\n",
    ")\n",
    "\n",
    "retriver = vector_store.as_retriever(search_kwargs={'score_threshold': 0.8})\n",
    "# chain_type_kwargs={\"prompt\": prompt},\n",
    "qa = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=retriver, memory=memory,  verbose=True)\n",
    "# qa = ConversationalRetrievalChain(llm=llm, retriever=retriver, memory=memory,  verbose=True, output_key='Resposta')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa.run('por que arthur dent foi despejado?')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
